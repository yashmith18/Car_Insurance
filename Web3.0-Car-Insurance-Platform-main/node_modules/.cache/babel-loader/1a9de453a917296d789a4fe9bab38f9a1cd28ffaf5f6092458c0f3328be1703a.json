{"ast":null,"code":"import errCode from 'err-code';\nimport { UnixFS } from 'ipfs-unixfs';\nimport persist from '../../utils/persist.js';\nimport { encode, prepare } from '@ipld/dag-pb';\nimport parallelBatch from 'it-parallel-batch';\nimport * as rawCodec from 'multiformats/codecs/raw';\nimport * as dagPb from '@ipld/dag-pb';\nimport dagFlat from './flat.js';\nimport dagBalanced from './balanced.js';\nimport dagTrickle from './trickle.js';\nimport bufferImporterFn from './buffer-importer.js';\nconst dagBuilders = {\n  flat: dagFlat,\n  balanced: dagBalanced,\n  trickle: dagTrickle\n};\nasync function* buildFileBatch(file, blockstore, options) {\n  let count = -1;\n  let previous;\n  let bufferImporter;\n  if (typeof options.bufferImporter === 'function') {\n    bufferImporter = options.bufferImporter;\n  } else {\n    bufferImporter = bufferImporterFn;\n  }\n  for await (const entry of parallelBatch(bufferImporter(file, blockstore, options), options.blockWriteConcurrency)) {\n    count++;\n    if (count === 0) {\n      previous = entry;\n      continue;\n    } else if (count === 1 && previous) {\n      yield previous;\n      previous = null;\n    }\n    yield entry;\n  }\n  if (previous) {\n    previous.single = true;\n    yield previous;\n  }\n}\nconst reduce = (file, blockstore, options) => {\n  async function reducer(leaves) {\n    if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n      const leaf = leaves[0];\n      if (file.mtime !== undefined || file.mode !== undefined) {\n        let buffer = await blockstore.get(leaf.cid);\n        leaf.unixfs = new UnixFS({\n          type: 'file',\n          mtime: file.mtime,\n          mode: file.mode,\n          data: buffer\n        });\n        buffer = encode(prepare({\n          Data: leaf.unixfs.marshal()\n        }));\n        leaf.cid = await persist(buffer, blockstore, {\n          ...options,\n          codec: dagPb,\n          hasher: options.hasher,\n          cidVersion: options.cidVersion\n        });\n        leaf.size = buffer.length;\n      }\n      return {\n        cid: leaf.cid,\n        path: file.path,\n        unixfs: leaf.unixfs,\n        size: leaf.size\n      };\n    }\n    const f = new UnixFS({\n      type: 'file',\n      mtime: file.mtime,\n      mode: file.mode\n    });\n    const links = leaves.filter(leaf => {\n      if (leaf.cid.code === rawCodec.code && leaf.size) {\n        return true;\n      }\n      if (leaf.unixfs && !leaf.unixfs.data && leaf.unixfs.fileSize()) {\n        return true;\n      }\n      return Boolean(leaf.unixfs && leaf.unixfs.data && leaf.unixfs.data.length);\n    }).map(leaf => {\n      if (leaf.cid.code === rawCodec.code) {\n        f.addBlockSize(leaf.size);\n        return {\n          Name: '',\n          Tsize: leaf.size,\n          Hash: leaf.cid\n        };\n      }\n      if (!leaf.unixfs || !leaf.unixfs.data) {\n        f.addBlockSize(leaf.unixfs && leaf.unixfs.fileSize() || 0);\n      } else {\n        f.addBlockSize(leaf.unixfs.data.length);\n      }\n      return {\n        Name: '',\n        Tsize: leaf.size,\n        Hash: leaf.cid\n      };\n    });\n    const node = {\n      Data: f.marshal(),\n      Links: links\n    };\n    const buffer = encode(prepare(node));\n    const cid = await persist(buffer, blockstore, options);\n    return {\n      cid,\n      path: file.path,\n      unixfs: f,\n      size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n    };\n  }\n  return reducer;\n};\nfunction fileBuilder(file, block, options) {\n  const dagBuilder = dagBuilders[options.strategy];\n  if (!dagBuilder) {\n    throw errCode(new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY');\n  }\n  return dagBuilder(buildFileBatch(file, block, options), reduce(file, block, options), options);\n}\nexport default fileBuilder;","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}