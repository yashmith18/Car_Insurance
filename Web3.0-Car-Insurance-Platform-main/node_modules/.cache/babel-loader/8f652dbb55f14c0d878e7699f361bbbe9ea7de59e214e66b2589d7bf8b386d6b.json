{"ast":null,"code":"import { encode, prepare } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport { createHAMT, Bucket } from 'hamt-sharding';\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n  get(name) {\n    return this._bucket.get(name);\n  }\n  childCount() {\n    return this._bucket.leafCount();\n  }\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield {\n        ...entry,\n        path: this.path\n      };\n    }\n  }\n}\nexport default DirSharded;\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n    if (!child) {\n      continue;\n    }\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n    if (child instanceof Bucket) {\n      let shard;\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n      if (!value.cid) {\n        continue;\n      }\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = encode(prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}